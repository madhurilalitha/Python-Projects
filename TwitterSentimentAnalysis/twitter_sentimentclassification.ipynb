{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of Tweet Sentiments on Weber Shandwick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This project is developed as a demonstration of my experience in handling unstructured data. The business case considered here is: \n",
    "\n",
    "\" To understand the online behavior of customers of \"Weber Shandwick\" using their Twitter Data \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of this project:\n",
    "\n",
    "    1) Find the percentage of Positive, Negative and Neutral Tweets\n",
    "    2) Analyze the tweets and understand the customer behavior for taking Decisions for optimizing customer satisfaction\n",
    "    3) Suggest the ideas to the business team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1 - Importing the dependenices and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Importing the dependencies\n",
    "\"re\" - for regular expression functionalities to handle the textual data\n",
    "\n",
    "tweepy - this is the python client for the official Twitter API\n",
    "\n",
    "tweepy's OAuthHandler - Twitter has the developer account who can download the tweets from twitter website. Every developer\n",
    "has a customer key and access token. When this valid combination is given in the program, it makes a call to the twitter API\n",
    "and download the required number of tweets accordingly\n",
    "\n",
    "textblob - this is the NLP library to handle the polarity(sentiment) of the textual data (here text data is tweets) '''\n",
    "\n",
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step -2 : Functionalities covered\n",
    "    \n",
    "    1) Validate the developer's account to download the tweets\n",
    "    2) Clean tweets using python regex\n",
    "    3) obtain the tweet's sentiment using python's textblob nlp library\n",
    "    4) Function to download tweets and parse them\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        consumer_key = 'SnnT3pizFAHViBKU6qE013XuY'\n",
    "        consumer_secret = 'dY7Gksp2yCvV5YxQMJjeTbAGvYRsBx831aQfccHhAsoRjOo7RJ'\n",
    "        access_token = '166258894-zjBbDnhNJPwL0b2jDGERUIyoa6QOrQF8iLfRzcrP'\n",
    "        access_token_secret = 'r7PVqYRAuI1Wo2awFwgJDxgFq1KHW4pn5jQrb3FWeAWbT'\n",
    " \n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # create OAuthHandler object\n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "            self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(self.auth)\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    " \n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    " \n",
    "    def get_tweets(self, query, count = 10):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    " \n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search(q = query, count = count)\n",
    " \n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    " \n",
    "                # saving text of tweet\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                # saving sentiment of tweet\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    " \n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    " \n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    " \n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 63.513513513513516 %\n",
      "Negative tweets percentage: 1.3513513513513513 %\n",
      "Neutral tweets percentage: 35.13513513513514 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "RT @WeberShandwick: Proud to be part of @InterpublicIPG who scored 100 on @HRC‚Äôs Corporate Equality Index. https://t.co/kWkD5LHJ6k #CEI2018‚Ä¶\n",
      "RT @PlankCenterPR: The Challenge for Emerging Leaders wraps day 2 with some amazing advice from keynote speaker @WeberShandwick‚Äôs @glennbed‚Ä¶\n",
      "RT @PlankCenterPR: @glennbeden @WeberShandwick And congratulations to @WeberShandwick on the 3-peat of being Chicago‚Äôs Top Workplaces. üëè\n",
      "Many thanks to the Dallas offices of @WeberShandwick and @Fleishman for hosting students from @UCO_MCOM this week.‚Ä¶ https://t.co/zCxRayRbmg\n",
      "@glennbeden @WeberShandwick And congratulations to @WeberShandwick on the 3-peat of being Chicago‚Äôs Top Workplaces. üëè\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "#FridayFeeling and #PRNewsInBrief, our weekly round-up of all the big things to have happened this week - featuring‚Ä¶ https://t.co/rguF6htCW2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # creating object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "    # calling function to get tweets\n",
    "    tweets = api.get_tweets(query = '@webershandwick', count = 100)\n",
    " \n",
    "    # picking positive tweets from tweets\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    \n",
    "    # percentage of positive tweets\n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "    \n",
    "    # picking negative tweets from tweets\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    \n",
    "    # percentage of negative tweets\n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "   \n",
    "    # percentage of neutral tweets\n",
    "    \n",
    "    print(\"Neutral tweets percentage: {} %\".format(100*(len(tweets) - len(ntweets) - len(ptweets))/len(tweets)))\n",
    " \n",
    "    # printing first 5 positive tweets\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets[:5]:\n",
    "        print(tweet['text'])\n",
    "     \n",
    "    # printing first 5 negative tweets\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets[:2]:\n",
    "        print(tweet['text'])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
