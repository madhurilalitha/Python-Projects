{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of Tweet Sentiments on Synovus Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This project is developed as a demonstration of my experience in handling unstructured data. The business case considered here is: \n",
    "\n",
    "\" To understand the online behavior of customers of \"Synovus Bank\" using their Twitter Data \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim of this project:\n",
    "\n",
    "    1) Find the percentage of Positive, Negative and Neutral Tweets\n",
    "    2) Analyze the tweets and understand the customer behavior for taking Decisions for optimizing customer satisfaction\n",
    "    3) Suggest the ideas to the business team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1 - Importing the dependenices and python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Importing the dependencies\n",
    "\"re\" - for regular expression functionalities to handle the textual data\n",
    "\n",
    "tweepy - this is the python client for the official Twitter API\n",
    "\n",
    "tweepy's OAuthHandler - Twitter has the developer account who can download the tweets from twitter website. Every developer\n",
    "has a customer key and access token. When this valid combination is given in the program, it makes a call to the twitter API\n",
    "and download the required number of tweets accordingly\n",
    "\n",
    "textblob - this is the NLP library to handle the polarity(sentiment) of the textual data (here text data is tweets) '''\n",
    "\n",
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step -2 : Functionalities covered\n",
    "    \n",
    "    1) Validate the developer's account to download the tweets\n",
    "    2) Clean tweets using python regex\n",
    "    3) obtain the tweet's sentiment using python's textblob nlp library\n",
    "    4) Function to download tweets and parse them\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        consumer_key = 'SnnT3pizFAHViBKU6qE013XuY'\n",
    "        consumer_secret = 'dY7Gksp2yCvV5YxQMJjeTbAGvYRsBx831aQfccHhAsoRjOo7RJ'\n",
    "        access_token = '166258894-zjBbDnhNJPwL0b2jDGERUIyoa6QOrQF8iLfRzcrP'\n",
    "        access_token_secret = 'r7PVqYRAuI1Wo2awFwgJDxgFq1KHW4pn5jQrb3FWeAWbT'\n",
    " \n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # create OAuthHandler object\n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "            self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(self.auth)\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    " \n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    " \n",
    "    def get_tweets(self, query, count = 10):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    " \n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search(q = query, count = count)\n",
    " \n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    " \n",
    "                # saving text of tweet\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                # saving sentiment of tweet\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    " \n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    " \n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    " \n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 56.25 %\n",
      "Negative tweets percentage: 20.833333333333332 %\n",
      "Neutral tweets percentage: 22.916666666666668 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "@synovus I heard the DJ was amazing! @WillRArd\n",
      "RT @synovus: We've hidden five $1,000 gift cards in east Atlanta near our new Reynoldstown branch. Find them Nov. 11., starting at 11 a.m!…\n",
      ".@synovus supporting #ChildProtectionCenter    in their mission to prevent child abuse &amp; provide intervention &amp; tre… https://t.co/eZCH8LRFo3\n",
      "@synovus Again: Do the right thing and give that $5000 to something other than your promotion. Such as helping the… https://t.co/tIQ1UNpIbQ\n",
      "RT @SDS: What are your favorite local traditions? We recently asked some fans. Presented by @Synovus, the bank of here. https://t.co/QlvLq1…\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "RT @synovus: Our brand conversion begins this week with new signs in Tampa/St. Pete! One down, 250+ to go! Chattanooga/Cohutta Bank is next…\n",
      "Langston's Davis is Fifth @synovus and @GeoSouthernCOE Teacher of the Game Winner https://t.co/dmkzqSIJqI… https://t.co/DcEPazEcCW\n",
      "This week's @COEAlumniSpotlight is a @synovus Teacher of the Game and the 2016 Langston Chapel Middle School Teache… https://t.co/SqyEMfI6UF\n",
      "@synovus Maybe you should give the $5000 to poor black families that have been pushed out of their family homes in… https://t.co/ckKR02qOzO\n",
      "The fucking Twitter ads from this place are every reason to hate gentrification. Stop this shit @synovus You're a f… https://t.co/kTuLjbIB5h\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # creating object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "    # calling function to get tweets\n",
    "    tweets = api.get_tweets(query = '@synovus', count = 1000)\n",
    " \n",
    "    # picking positive tweets from tweets\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "    \n",
    "    # percentage of positive tweets\n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "    \n",
    "    # picking negative tweets from tweets\n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "    \n",
    "    # percentage of negative tweets\n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "   \n",
    "    # percentage of neutral tweets\n",
    "    \n",
    "    print(\"Neutral tweets percentage: {} %\".format(100*(len(tweets) - len(ntweets) - len(ptweets))/len(tweets)))\n",
    " \n",
    "    # printing first 5 positive tweets\n",
    "    print(\"\\n\\nPositive tweets:\")\n",
    "    for tweet in ptweets[:5]:\n",
    "        print(tweet['text'])\n",
    "     \n",
    "    # printing first 5 negative tweets\n",
    "    print(\"\\n\\nNegative tweets:\")\n",
    "    for tweet in ntweets[:\n",
    "                         5]:\n",
    "        print(tweet['text'])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
